{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b5d2e3c-fef5-40da-be14-3ee736187e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepface\n",
      "  Downloading deepface-0.0.90-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: requests>=2.27.1 in ./venv_deepface/lib/python3.8/site-packages (from deepface) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in ./venv_deepface/lib/python3.8/site-packages (from deepface) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.23.4 in ./venv_deepface/lib/python3.8/site-packages (from deepface) (2.0.3)\n",
      "Collecting gdown>=3.10.1 (from deepface)\n",
      "  Using cached gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tqdm>=4.30.0 (from deepface)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting Pillow>=5.2.0 (from deepface)\n",
      "  Using cached pillow-10.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in ./venv_deepface/lib/python3.8/site-packages (from deepface) (4.9.0.80)\n",
      "Collecting tensorflow>=1.9.0 (from deepface)\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting keras>=2.2.0 (from deepface)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting Flask>=1.1.2 (from deepface)\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting mtcnn>=0.1.0 (from deepface)\n",
      "  Using cached mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting retina-face>=0.0.1 (from deepface)\n",
      "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fire>=0.4.0 (from deepface)\n",
      "  Using cached fire-0.6.0-py2.py3-none-any.whl\n",
      "Collecting gunicorn>=20.1.0 (from deepface)\n",
      "  Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: six in ./venv_deepface/lib/python3.8/site-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
      "Collecting termcolor (from fire>=0.4.0->deepface)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from Flask>=1.1.2->deepface)\n",
      "  Downloading werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./venv_deepface/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask>=1.1.2->deepface)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from Flask>=1.1.2->deepface)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask>=1.1.2->deepface)\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in ./venv_deepface/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (7.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv_deepface/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
      "Collecting filelock (from gdown>=3.10.1->deepface)\n",
      "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in ./venv_deepface/lib/python3.8/site-packages (from gunicorn>=20.1.0->deepface) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_deepface/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_deepface/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv_deepface/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_deepface/lib/python3.8/site-packages (from requests>=2.27.1->deepface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv_deepface/lib/python3.8/site-packages (from requests>=2.27.1->deepface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_deepface/lib/python3.8/site-packages (from requests>=2.27.1->deepface) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv_deepface/lib/python3.8/site-packages (from requests>=2.27.1->deepface) (2024.2.2)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=1.9.0->deepface)\n",
      "  Downloading grpcio-1.62.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow>=1.9.0->deepface)\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras>=2.2.0 (from deepface)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy>=1.14.0 (from deepface)\n",
      "  Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in ./venv_deepface/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (39.0.1)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=1.9.0->deepface)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv_deepface/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->Flask>=1.1.2->deepface) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv_deepface/lib/python3.8/site-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (2.1.5)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting setuptools (from tensorflow>=1.9.0->deepface)\n",
      "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv_deepface/lib/python3.8/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=3.10.1->deepface)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=1.9.0->deepface)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading deepface-0.0.90-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "Using cached pillow-10.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
      "Using cached tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.62.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, Werkzeug, typing-extensions, tqdm, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, setuptools, PySocks, pyasn1, protobuf, Pillow, oauthlib, numpy, keras, itsdangerous, gunicorn, grpcio, google-pasta, gast, filelock, click, cachetools, blinker, absl-py, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, markdown, h5py, Flask, fire, astunparse, mtcnn, google-auth, gdown, google-auth-oauthlib, tensorboard, tensorflow, retina-face, deepface\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 39.0.1\n",
      "    Uninstalling setuptools-39.0.1:\n",
      "      Successfully uninstalled setuptools-39.0.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "Successfully installed Flask-3.0.3 Pillow-10.3.0 PySocks-1.7.1 Werkzeug-3.0.2 absl-py-2.1.0 astunparse-1.6.3 blinker-1.7.0 cachetools-5.3.3 click-8.1.7 deepface-0.0.90 filelock-3.13.4 fire-0.6.0 flatbuffers-24.3.25 gast-0.4.0 gdown-5.1.0 google-auth-2.29.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.62.2 gunicorn-22.0.0 h5py-3.11.0 itsdangerous-2.2.0 keras-2.13.1 libclang-18.1.1 markdown-3.6 mtcnn-0.1.1 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 requests-oauthlib-2.0.0 retina-face-0.0.17 rsa-4.9 setuptools-69.5.1 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 tqdm-4.66.2 typing-extensions-4.5.0 wheel-0.43.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a58ecc9-8ac1-4825-aba6-801dcfcf5c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 17:28:17.340165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-27 17:28:18.227237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d7621f6-93d1-4e2c-b69a-882d6058ae5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Track</th>\n",
       "      <th>Score</th>\n",
       "      <th>S</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Encoding</th>\n",
       "      <th>GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>26.798439</td>\n",
       "      <td>754.324982</td>\n",
       "      <td>209.635254</td>\n",
       "      <td>[-0.09836239367723465, 0.13868828117847443, 0....</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>26.798439</td>\n",
       "      <td>755.640533</td>\n",
       "      <td>209.537827</td>\n",
       "      <td>[-0.08967693895101547, 0.13070103526115417, 0....</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.798439</td>\n",
       "      <td>757.025818</td>\n",
       "      <td>209.537827</td>\n",
       "      <td>[-0.08625832945108414, 0.09812241792678833, 0....</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.82</td>\n",
       "      <td>26.798439</td>\n",
       "      <td>757.565979</td>\n",
       "      <td>209.489815</td>\n",
       "      <td>[-0.07489930093288422, 0.09846128523349762, 0....</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1.18</td>\n",
       "      <td>26.852104</td>\n",
       "      <td>757.937622</td>\n",
       "      <td>209.489815</td>\n",
       "      <td>[-0.09827088564634323, 0.129554882645607, 0.03...</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>4475</td>\n",
       "      <td>29</td>\n",
       "      <td>0.92</td>\n",
       "      <td>28.817108</td>\n",
       "      <td>743.650055</td>\n",
       "      <td>222.889732</td>\n",
       "      <td>[-0.10731110721826553, 0.09929558634757996, -0...</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>4476</td>\n",
       "      <td>29</td>\n",
       "      <td>0.92</td>\n",
       "      <td>28.811111</td>\n",
       "      <td>743.650055</td>\n",
       "      <td>222.869759</td>\n",
       "      <td>[-0.1052149161696434, 0.1109282374382019, -0.0...</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>4477</td>\n",
       "      <td>29</td>\n",
       "      <td>0.92</td>\n",
       "      <td>28.773651</td>\n",
       "      <td>743.650055</td>\n",
       "      <td>221.797035</td>\n",
       "      <td>[-0.10879873484373093, 0.11200059205293655, -0...</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>4478</td>\n",
       "      <td>29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>28.598061</td>\n",
       "      <td>743.650055</td>\n",
       "      <td>220.504875</td>\n",
       "      <td>[-0.09570878744125366, 0.10964033007621765, 0....</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4479</td>\n",
       "      <td>29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>28.324181</td>\n",
       "      <td>743.650055</td>\n",
       "      <td>219.060310</td>\n",
       "      <td>[-0.10337416082620621, 0.12789762020111084, 0....</td>\n",
       "      <td>Speaker_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2047 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frame  Track  Score          S           X           Y  \\\n",
       "0        22      2   0.12  26.798439  754.324982  209.635254   \n",
       "1        23      2   0.32  26.798439  755.640533  209.537827   \n",
       "2        24      2   0.60  26.798439  757.025818  209.537827   \n",
       "3        25      2   0.82  26.798439  757.565979  209.489815   \n",
       "4        26      2   1.18  26.852104  757.937622  209.489815   \n",
       "...     ...    ...    ...        ...         ...         ...   \n",
       "2042   4475     29   0.92  28.817108  743.650055  222.889732   \n",
       "2043   4476     29   0.92  28.811111  743.650055  222.869759   \n",
       "2044   4477     29   0.92  28.773651  743.650055  221.797035   \n",
       "2045   4478     29   0.60  28.598061  743.650055  220.504875   \n",
       "2046   4479     29   0.22  28.324181  743.650055  219.060310   \n",
       "\n",
       "                                               Encoding         GT  \n",
       "0     [-0.09836239367723465, 0.13868828117847443, 0....  Speaker_3  \n",
       "1     [-0.08967693895101547, 0.13070103526115417, 0....  Speaker_3  \n",
       "2     [-0.08625832945108414, 0.09812241792678833, 0....  Speaker_3  \n",
       "3     [-0.07489930093288422, 0.09846128523349762, 0....  Speaker_3  \n",
       "4     [-0.09827088564634323, 0.129554882645607, 0.03...  Speaker_3  \n",
       "...                                                 ...        ...  \n",
       "2042  [-0.10731110721826553, 0.09929558634757996, -0...  Speaker_3  \n",
       "2043  [-0.1052149161696434, 0.1109282374382019, -0.0...  Speaker_3  \n",
       "2044  [-0.10879873484373093, 0.11200059205293655, -0...  Speaker_3  \n",
       "2045  [-0.09570878744125366, 0.10964033007621765, 0....  Speaker_3  \n",
       "2046  [-0.10337416082620621, 0.12789762020111084, 0....  Speaker_3  \n",
       "\n",
       "[2047 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"ESPN_1\"\n",
    "df_gt = pd.read_excel(\"../del_later/gt_3_video.xlsx\")\n",
    "with open(f\"/vol3/sunil/output/video_temp/{file_name}/pywork/encoding_df.pckl\", \"rb\") as fil:\n",
    "    encoding_df = pickle.load(fil)\n",
    "temp_df = encoding_df.merge(df_gt[df_gt[\"Filename\"] == file_name][[\"Track\", \"GT\"]])\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07b0885-5ede-41d2-bcb9-5864702082ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol3/sunil/output/video_temp/ESPN_1/pyframes/00022.jpg\n"
     ]
    }
   ],
   "source": [
    "print(\"/vol3/sunil/output/video_temp/ESPN_1/pyframes/%05d.jpg\" % 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f23448d-a739-4adb-99be-e60d8cbe5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 22\n",
    "image = cv2.imread(\"/vol3/sunil/output/video_temp/ESPN_1/pyframes/%06d.jpg\" % 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4275fdd-9539-4aec-a197-6569031a1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = int(temp_df[temp_df[\"Frame\"] == 22][\"S\"].values[0])\n",
    "x = int(temp_df[temp_df[\"Frame\"] == 22][\"X\"].values[0])\n",
    "y = int(temp_df[temp_df[\"Frame\"] == 22][\"Y\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d291f07c-1147-4da6-8b37-6a0ab8d750c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (804563667.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    face_embedding = DeepFace.represent(face, model_name=\"Facenet)\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "face = image[y-s:y+s, x-s:x+s]\n",
    "face_embedding = DeepFace.represent(face, model_name=\"Facenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8258e35e-94b4-447a-8c64-26c0197b1222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"frame_22_with_rect.jpg\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5201e2f-21ff-4f69-97b2-100bdfc52394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 17:32:00.571435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.1.1 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-04-27 17:32:00.572748: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at conv_ops_impl.h:770 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer 'conv2d' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D] name: \n\nCall arguments received by layer 'conv2d' (type Conv2D):\n  • inputs=tf.Tensor(shape=(1, 226, 226, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m face \u001b[38;5;241m=\u001b[39m image[y:y\u001b[38;5;241m+\u001b[39ms, x:x\u001b[38;5;241m+\u001b[39ms]\n\u001b[0;32m----> 2\u001b[0m face_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/Stuff/Combined/scene_detect_test/venv_deepface/lib/python3.8/site-packages/deepface/DeepFace.py:381\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresent\u001b[39m(\n\u001b[1;32m    329\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    330\u001b[0m     model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG-Face\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     normalization: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    Represent facial images as multi-dimensional vector embeddings.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m            to 'skip', the confidence will be 0 and is nonsensical.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/Stuff/Combined/scene_detect_test/venv_deepface/lib/python3.8/site-packages/deepface/modules/representation.py:112\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# custom normalization\u001b[39;00m\n\u001b[1;32m    110\u001b[0m img \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mnormalize_input(img\u001b[38;5;241m=\u001b[39mimg, normalization\u001b[38;5;241m=\u001b[39mnormalization)\n\u001b[0;32m--> 112\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m resp_obj \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m resp_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/projects/Stuff/Combined/scene_detect_test/venv_deepface/lib/python3.8/site-packages/deepface/basemodels/VGGFace.py:66\u001b[0m, in \u001b[0;36mVggFaceClient.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mGenerates embeddings using the VGG-Face model.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    This method incorporates an additional normalization layer,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    embeddings (list): multi-dimensional vector\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# model.predict causes memory issue when it is called in a for loop\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# embedding = model.predict(img, verbose=0)[0].tolist()\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# having normalization layer in descriptor troubles for some gpu users (e.g. issue 957, 966)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# instead we are now calculating it with traditional way not with keras backend\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     67\u001b[0m embedding \u001b[38;5;241m=\u001b[39m verification\u001b[38;5;241m.\u001b[39ml2_normalize(embedding)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/projects/Stuff/Combined/scene_detect_test/venv_deepface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/projects/Stuff/Combined/scene_detect_test/venv_deepface/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer 'conv2d' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D] name: \n\nCall arguments received by layer 'conv2d' (type Conv2D):\n  • inputs=tf.Tensor(shape=(1, 226, 226, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "face = image[y:y+s, x:x+s]\n",
    "face_embedding = DeepFace.represent(face, enforce_detection=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
