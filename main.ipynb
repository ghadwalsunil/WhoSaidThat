{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00831ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "# venv\n",
    "import torch\n",
    "import datetime as dt\n",
    "print(torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19975759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, glob\n",
    "from shutil import rmtree\n",
    "import cv2\n",
    "import demoTalkNetMod\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import srt\n",
    "import whisper\n",
    "\n",
    "from stable_whisper import modify_model\n",
    "from pyannote.core import Segment, Annotation\n",
    "from pyannote.core import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = logging.getLogger(\"transcribe\")\n",
    "# sys.path.append(os.path.abspath(\"TalkNet-ASD/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f945ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_plot(speaker_timelines):\n",
    "    custom_diarization = Annotation()\n",
    "    \n",
    "    for speaker_key in speaker_timelines.keys():\n",
    "        for timeline in speaker_timelines[speaker_key]:\n",
    "            custom_diarization[Segment(timeline[0], timeline[1])] = speaker_key\n",
    "\n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 2))\n",
    "\n",
    "    # Plot the custom diarization result\n",
    "    notebook.plot_annotation(custom_diarization, ax, legend=True)\n",
    "\n",
    "    # Customize the plot (if needed)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_yticks([])  # To hide the y-axis\n",
    "\n",
    "    # Save the figure\n",
    "#     fig.savefig('custom_diarization_plot.png', bbox_inches='tight')\n",
    "\n",
    "    # Show the figure (optional)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def get_openai_model(model_name=\"base\"):\n",
    "    # initialize model\n",
    "    logging.info(f\"Initializing openai's '{model_name} 'model\")\n",
    "    if model_name in [\n",
    "        \"tiny.en\",\n",
    "        \"tiny\",\n",
    "        \"base.en\",\n",
    "        \"base\",\n",
    "        \"small.en\",\n",
    "        \"small\",\n",
    "        \"medium.en\",\n",
    "        \"medium\",\n",
    "        \"large\",\n",
    "    ]:\n",
    "        try:\n",
    "            model = whisper.load_model(model_name)\n",
    "            # Using the stable whisper to modifiy the model for better timestamps accuracy\n",
    "            modify_model(model)\n",
    "            logging.info(\"Model was successfully initialized\")\n",
    "        except:\n",
    "            logging.error(\"Unable to initialize openai model\")\n",
    "            return None\n",
    "    else:\n",
    "        logging.error(\n",
    "            \"Model  not found; available models = ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_openai_transcription(file_path, model):\n",
    "    logging.info(f\"Generating transcription for file - {file_path}\")\n",
    "\n",
    "    decode_options = dict(language=\"en\")\n",
    "    transcribe_options = dict(task=\"transcribe\", **decode_options)\n",
    "    output = model.transcribe(file_path, **transcribe_options)\n",
    "\n",
    "    transcriptions = {}\n",
    "\n",
    "    for num, s in enumerate(output.segments):\n",
    "        transcriptions[num] = []\n",
    "        for word in s.words:\n",
    "            transcriptions[num].append(\n",
    "                {\n",
    "                    \"text\": s.text,\n",
    "                    \"segment_start\": s.start,\n",
    "                    \"segment_end\": s.end,\n",
    "                    \"word\": word.word,\n",
    "                    \"word_start\": word.start,\n",
    "                    \"word_end\": word.end,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for key, words in transcriptions.items():\n",
    "        for word in words:\n",
    "            row = {\n",
    "                \"segment_id\": key,\n",
    "                \"segment_text\": word[\"text\"],\n",
    "                \"segment_start\": word[\"segment_start\"],\n",
    "                \"segment_end\": word[\"segment_end\"],\n",
    "                \"word\": word[\"word\"],\n",
    "                \"word_start\": word[\"word_start\"],\n",
    "                \"word_end\": word[\"word_end\"],\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_overlap(intervals1, intervals2):\n",
    "    overlap = 0\n",
    "    total_duration1 = 0\n",
    "    total_duration2 = 0\n",
    "\n",
    "    # Calculate the total duration of intervals in intervals1\n",
    "    for start, end in intervals1:\n",
    "        total_duration1 += end - start\n",
    "\n",
    "    # Calculate the total duration of intervals in intervals2 and find the overlap\n",
    "    for start, end in intervals2:\n",
    "        total_duration2 += end - start\n",
    "        for s1, e1 in intervals1:\n",
    "            common_start = max(s1, start)\n",
    "            common_end = min(e1, end)\n",
    "            if common_start < common_end:\n",
    "                overlap += common_end - common_start\n",
    "\n",
    "    # Calculate the percentage of overlap with respect to intervals1\n",
    "    percentage_overlap1 = (overlap / total_duration1) * 100\n",
    "\n",
    "    # Calculate the percentage of overlap with respect to intervals2\n",
    "    percentage_overlap2 = (overlap / total_duration2) * 100\n",
    "\n",
    "    return percentage_overlap1, percentage_overlap2\n",
    "\n",
    "\n",
    "def get_video_to_audio_mapping(video_output, audio_output):\n",
    "    video_audio_mapping = {}\n",
    "    for audio_speaker in audio_output.keys():\n",
    "        for video_speaker in video_output.keys():\n",
    "            video_overlap, _ = find_overlap(video_output[video_speaker], audio_output[audio_speaker])\n",
    "            if video_overlap > 80:\n",
    "                video_audio_mapping[audio_speaker] = video_speaker\n",
    "                break\n",
    "    return video_audio_mapping\n",
    "\n",
    "def get_segment_to_speaker_mapping(segment_start, segment_end, speaker_mapping, audio_output):\n",
    "    \n",
    "    final_speaker = None\n",
    "    max_overlap = 0\n",
    "    \n",
    "    for audio_speaker in audio_output.keys():\n",
    "        segment_overlap, _ = find_overlap([(segment_start, segment_end)], audio_output[audio_speaker])\n",
    "        if segment_overlap > max_overlap:\n",
    "            final_speaker = audio_speaker\n",
    "            max_overlap = segment_overlap\n",
    "            \n",
    "    if final_speaker is None:\n",
    "        return \"Unknown\", max_overlap\n",
    "    else:\n",
    "        if final_speaker in speaker_mapping.keys():\n",
    "            return speaker_mapping[final_speaker], max_overlap\n",
    "        else:\n",
    "            return final_speaker, max_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bff394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, args_dict):\n",
    "        self.__dict__.update(args_dict)\n",
    "\n",
    "args_dict = {\n",
    "    \"videoName\": \"Video3\",\n",
    "    \"videoFolder\":\"Videos\",\n",
    "    \"pretrainModel\":\"pretrain_TalkSet.model\",\n",
    "    \"nDataLoaderThread\":10,\n",
    "    \"facedetScale\":0.25,\n",
    "    \"minTrack\":10,\n",
    "    \"numFailedDet\":10,\n",
    "    \"minFaceSize\":1,\n",
    "    \"cropScale\":0.40,\n",
    "    \"start\":0,\n",
    "    \"duration\":0,\n",
    "    \"evalCol\":False,\n",
    "    \"colSavePath\":\"/data08/col\",\n",
    "}\n",
    "\n",
    "args = Args(args_dict)\n",
    "\n",
    "if os.path.isfile(args.pretrainModel) == False:  # Download the pretrained model\n",
    "    Link = \"1AbN9fCf9IexMxEKXLQY2KYBlb-IhSEea\"\n",
    "    cmd = \"gdown --id %s -O %s\" % (Link, args.pretrainModel)\n",
    "    subprocess.call(cmd, shell=True, stdout=None)\n",
    "\n",
    "args.videoPath = glob.glob(os.path.join(args.videoFolder, args.videoName + \".*\"))[0]\n",
    "args.savePath = os.path.join(args.videoFolder, args.videoName)\n",
    "args.audioPath = os.path.join(args.savePath, \"pyavi\", \"audio.wav\")\n",
    "video = cv2.VideoCapture(args.videoPath)\n",
    "args.frameRate = video.get(cv2.CAP_PROP_FPS)\n",
    "video.release()\n",
    "print(args.frameRate)\n",
    "\n",
    "\n",
    "model_name_openai = \"base.en\"\n",
    "model = get_openai_model(model_name_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046f06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 23:39:49 Extract the video and save in Videos/Video3/pyavi/video.avi \n",
      "2024-01-03 23:39:49 Extract the audio and save in Videos/Video3/pyavi/audio.wav \n",
      "2024-01-03 23:39:55 Extract the frames and save in Videos/Video3/pyframes \n",
      "ERROR:pyscenedetect:VideoManager is deprecated and will be removed.\n",
      "INFO:pyscenedetect:Loaded 1 video, framerate: 25.000 FPS, resolution: 1920 x 1080\n",
      "INFO:pyscenedetect:Downscale factor set to 7, effective resolution: 274 x 154\n",
      "INFO:pyscenedetect:Detecting scenes...\n",
      "ERROR:pyscenedetect:`base_timecode` argument is deprecated and has no effect.\n",
      "Videos/Video3/pyavi/video.avi - scenes detected 10\n",
      "2024-01-03 23:39:59 Scene detection and save in Videos/Video3/pywork \n",
      "2024-01-03 23:41:00 Face detection and save in Videos/Video3/pywork \n",
      "2024-01-03 23:41:00 Face track and detected 11 tracks \n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:26<00:00,  2.41s/it]\n",
      "2024-01-03 23:41:27 Face Crop and saved in Videos/Video3/pycrop tracks \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-03 23:41:27 Model para number = 15.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model pretrain_TalkSet.model loaded from previous state! \n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  2.87it/s]\n",
      "2024-01-03 23:41:31 Scores extracted and saved in Videos/Video3/pywork \n"
     ]
    }
   ],
   "source": [
    "vidTracks, scores, args = demoTalkNetMod.preprocess(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c099b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 650/650 [03:22<00:00,  3.20tracks/s]\n",
      "2024-01-03 23:45:16 Face encoding generation completed"
     ]
    }
   ],
   "source": [
    "df = demoTalkNetMod.get_track_face_encodings(vidTracks, scores, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00553950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f\"{args.savePath}/{args.videoName}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947befc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{args.savePath}/{args.videoName}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941afa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1  27]\n",
      " [  0 428]\n",
      " [  1 195]]\n"
     ]
    }
   ],
   "source": [
    "# 001 - eps=0.4, min_samples = 4\n",
    "# PL - eps=0.5, min_samples = 200\n",
    "# Video3 - eps=0.5, min_samples = 100\n",
    "# Video2 - eps=0.5, min_samples = 100\n",
    "# Choose DBSCAN parameters\n",
    "eps = 0.5\n",
    "min_samples = 100\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "clusters = dbscan.fit_predict(df[\"Encoding\"].to_list())\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70667dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Clusters\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d196210",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = demoTalkNetMod.get_final_tracks(df, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a35afd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPEAKER_00': [(0.0, 1.16),\n",
       "  (9.36, 10.32),\n",
       "  (10.6, 21.68),\n",
       "  (22.52, 22.4),\n",
       "  (28.72, 28.84),\n",
       "  (30.2, 30.44),\n",
       "  (34.6, 35.12)],\n",
       " 'SPEAKER_01': [(5.2, 5.36),\n",
       "  (5.52, 8.84),\n",
       "  (9.2, 9.24),\n",
       "  (25.88, 27.88),\n",
       "  (31.84, 33.8)]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# video_output = {\n",
    "#     \"SPEAKER_00\": [(3.92, 5.64), (6.4, 6.56), (7.32, 12.68), (180.72, 183.44)],\n",
    "#     \"SPEAKER_01\": [\n",
    "#         (32.76, 45.48),\n",
    "#         (45.84, 81.76),\n",
    "#         (81.92, 82.24),\n",
    "#         (82.68, 87.64),\n",
    "#         (208.0, 238.12),\n",
    "#         (238.76, 243.04),\n",
    "#         (243.36, 249.96),\n",
    "#     ],\n",
    "#     \"SPEAKER_02\": [(87.72, 89.24), (90.24, 91.48), (91.6, 105.52), (107.24, 115.24), (157.0, 175.84), (177.56, 179.8)],\n",
    "# }\n",
    "video_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01aeb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "from pyannote.audio import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde54b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.0\",\n",
    "                                               use_auth_token=os.getenv('HUGGINGFACE_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ee9200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 23:48:54.231911744 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2024-01-03 23:48:54.231943402 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f0613fef100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "pretrained_pipeline.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3950ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Videos/Video3/pyavi/audio.wav'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.audioPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a5eb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization = pretrained_pipeline(args.audioPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7a1f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPEAKER_00': [(0.008488964346349746, 1.2478777589134127),\n",
       "  (8.497453310696097, 9.906621392190154),\n",
       "  (10.619694397283531, 22.53820033955858),\n",
       "  (28.803056027164686, 28.98981324278438),\n",
       "  (29.006791171477083, 29.56706281833616),\n",
       "  (30.61969439728353, 30.908319185059426),\n",
       "  (33.43803056027165, 35.135823429541595)],\n",
       " 'SPEAKER_01': [(0.008488964346349746, 5.254668930390492),\n",
       "  (5.577249575551782, 8.310696095076402),\n",
       "  (20.874363327674025, 21.24787775891341),\n",
       "  (21.6044142614601, 21.859083191850594),\n",
       "  (22.53820033955858, 28.803056027164686),\n",
       "  (28.98981324278438, 34.37181663837012)]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_output = {}\n",
    "for duration,_, speaker_key in diarization.itertracks(yield_label=True):\n",
    "    if speaker_key in audio_output.keys():\n",
    "        audio_output[speaker_key].append((duration.start,duration.end))\n",
    "    else:\n",
    "        audio_output[speaker_key] = [(duration.start,duration.end)]\n",
    "audio_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63e6ab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_annotation_plot(video_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "881ed13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_annotation_plot(audio_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5822883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPEAKER_00': 'SPEAKER_00', 'SPEAKER_01': 'SPEAKER_01'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_audio_mapping = get_video_to_audio_mapping(video_output, audio_output)\n",
    "video_audio_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfac2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 38.13/38.13 [00:03<00:00, 11.46sec/s]\n"
     ]
    }
   ],
   "source": [
    "df = generate_openai_transcription(args.videoPath, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7bbe673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"segment_end\"] = df.apply(\n",
    "    lambda row: (row[\"segment_end\"] + 0.1) if row[\"segment_start\"] == row[\"segment_end\"] else row[\"segment_end\"], axis=1\n",
    ")\n",
    "df[\"word_end\"] = df.apply(\n",
    "    lambda row: (row[\"word_end\"] + 0.1) if row[\"word_start\"] == row[\"word_end\"] else row[\"word_end\"], axis=1\n",
    ")\n",
    "segment_df = df[[\"segment_id\", \"segment_text\", \"segment_start\", \"segment_end\"]].drop_duplicates().reset_index(drop=True)\n",
    "word_df = df[[\"segment_id\", \"word\", \"word_start\", \"word_end\"]]\n",
    "segment_df[\"speaker_output\"] = segment_df.apply(\n",
    "    lambda row: get_segment_to_speaker_mapping(\n",
    "        row[\"segment_start\"], row[\"segment_end\"], video_audio_mapping, audio_output\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "segment_df[\"speaker_key\"] = segment_df[\"speaker_output\"].apply(lambda x: x[0])\n",
    "segment_df[\"speaker_confidence\"] = segment_df[\"speaker_output\"].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e80eeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_df[\"Subtitles\"] = segment_df.apply(\n",
    "    lambda row: srt.Subtitle(\n",
    "        index=row[\"segment_id\"] + 1,\n",
    "        start=timedelta(seconds=row[\"segment_start\"] - 0.1 if row[\"segment_start\"] > 0.1 else row[\"segment_start\"]),\n",
    "        end=timedelta(seconds=row[\"segment_end\"] + 0.1),\n",
    "        content=f\"{row['speaker_key']}: {row['segment_text']}\"\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d42873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If name mapping known\n",
    "name_mapping = {\"SPEAKER_00\": \"Trump\", \"SPEAKER_01\": \"Piers\"}\n",
    "segment_df[\"Subtitles\"] = segment_df.apply(\n",
    "    lambda row: srt.Subtitle(\n",
    "        index=row[\"segment_id\"] + 1,\n",
    "        start=timedelta(seconds=row[\"segment_start\"] - 0.1 if row[\"segment_start\"] > 0.1 else row[\"segment_start\"]),\n",
    "        end=timedelta(seconds=row[\"segment_end\"] + 0.1),\n",
    "        content=f\"{name_mapping[row['speaker_key']]}: {row['segment_text']}\"\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e994173",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_string = srt.compose(segment_df[\"Subtitles\"].to_list())\n",
    "with open(os.path.join(args.savePath, args.videoName + datetime.now().strftime(\"_%Y%m%d_%H%M%S\") + \".srt\"),\n",
    "          \"w\",\n",
    "         ) as f:\n",
    "    f.write(srt_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
